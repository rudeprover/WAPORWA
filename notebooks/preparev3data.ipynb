{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WaPOR v3 Data Collection and Preparation\n",
    "This notebook downloads WaPOR v3 data and prepares it for water accounting analysis.\n",
    "\n",
    "**Key updates in v3:**\n",
    "- No API token required\n",
    "- Direct COG-based downloads via GDAL\n",
    "- Faster and more reliable data access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Functions and Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Modules imported successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "from osgeo import gdal\n",
    "import osr\n",
    "\n",
    "# Add WAPORWA modules to path\n",
    "# modules_path = r'D:\\Papers and Journals\\WAPORWA\\modules'  # Change to your modules path\n",
    "# sys.path.insert(0, modules_path)\n",
    "\n",
    "# Import WA modules\n",
    "import WA\n",
    "from WA.pickle_basin import pickle_in, pickle_out\n",
    "\n",
    "print(\"✓ Modules imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WaPOR v3 module loaded\n",
      "No API token required - uses public COG files\n",
      "Use list_available_mapsets() to see all available datasets\n",
      "\n",
      "Available WaPOR v3 Mapsets:\n",
      "--------------------------------------------------------------------------------\n",
      "L1-AETI-A            - Actual EvapoTranspiration and Interception (Global - Annual - 300m)\n",
      "L1-AETI-D            - Actual EvapoTranspiration and Interception (Global - Dekadal - 300m)\n",
      "L1-AETI-M            - Actual EvapoTranspiration and Interception (Global - Monthly - 300m)\n",
      "L1-E-A               - Evaporation (Global - Annual - 300m)\n",
      "L1-E-D               - Evaporation (Global - Dekadal - 300m)\n",
      "L1-GBWP-A            - Gross biomass water productivity (Annual - 300m)\n",
      "L1-I-A               - Interception (Global - Annual - 300m)\n",
      "L1-I-D               - Interception (Global - Dekadal - 300m)\n",
      "L1-NBWP-A            - Net biomass water productivity (Annual - 300m)\n",
      "L1-NPP-D             - Net Primary Production (Global - Dekadal - 300m)\n",
      "L1-NPP-M             - Net Primary Production (Global - Monthly - 300m)\n",
      "L1-PCP-A             - Precipitation (Global - Annual - Approximately 5km)\n",
      "L1-PCP-D             - Precipitation (Global - Dekadal - Approximately 5km)\n",
      "L1-PCP-E             - Precipitation (Global - Daily - Approximately 5km)\n",
      "L1-PCP-M             - Precipitation (Global - Montly - Approximately 5km)\n",
      "L1-QUAL-LST-D        - Quality land surface temperature (Global - Dekadal - 300m)\n",
      "L1-QUAL-NDVI-D       - Quality of Normalized Difference Vegetation Index (Global - Dekadal - 300m)\n",
      "L1-RET-A             - Reference Evapotranspiration (Global - Annual - Approximately 30km)\n",
      "L1-RET-D             - Reference Evapotranspiration (Global - Dekadal - Approximately 30km)\n",
      "L1-RET-E             - Reference Evapotranspiration (Global - Daily - Approximately 30km)\n",
      "L1-RET-M             - Reference Evapotranspiration (Global - Monthly - Approximately 30km)\n",
      "L1-RSM-D             - Relative Soil Moisture (Global - Dekadal - 300m)\n",
      "L1-T-A               - Transpiration (Global - Annual - 300m)\n",
      "L1-T-D               - Transpiration (Global - Dekadal - 300m)\n",
      "L1-TBP-A             - Total Biomass Production (Global - Annual - 300m)\n",
      "L2-AETI-A            - Actual EvapoTranspiration and Interception (National - Annual - 100m)\n",
      "L2-AETI-D            - Actual EvapoTranspiration and Interception (National - Dekadal - 100m)\n",
      "L2-AETI-M            - Actual EvapoTranspiration and Interception (National - Monthly - 100m)\n",
      "L2-E-A               - Evaporation (National - Annual - 100m)\n",
      "L2-E-D               - Evaporation (National - Dekadal - 100m)\n",
      "L2-GBWP-A            - Gross biomass water productivity (Annual - 100m)\n",
      "L2-I-A               - Interception (National - Annual - 100m)\n",
      "L2-I-D               - Interception (National - Dekadal - 100m)\n",
      "L2-NBWP-A            - Net biomass water productivity (Annual - 100m)\n",
      "L2-NPP-D             - Net Primary Production (National - Dekadal - 100m)\n",
      "L2-NPP-M             - Net Primary Production (National - Monthly - 100m)\n",
      "L2-QUAL-NDVI-D       - Quality of normalized difference vegetation index (National - Dekadal - 100m)\n",
      "L2-RSM-D             - Relative Soil Moisture (National - Dekadal - 100m)\n",
      "L2-T-A               - Transpiration (National - Annual - 100m)\n",
      "L2-T-D               - Transpiration (National - Dekadal - 100m)\n",
      "L2-TBP-A             - Total Biomass Production (Global - Annual - 100m)\n",
      "PAL-CROP-TYPE        - Crop map of spring and winter growing seasons (Jericho, Palestine - 2023-2024 - 10m)\n",
      "\n",
      "Total: 42 mapsets\n",
      "✓ WaPOR module location: D:\\Papers and Journals\\WAPORWA\\modules\\WaPOR\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, r\"D:\\Papers and Journals\\WAPORWA\\modules\")\n",
    "\n",
    "import WaPOR\n",
    "WaPOR.list_available_mapsets()\n",
    "\n",
    "print(f\"✓ WaPOR module location: {WaPOR.__file__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Basin Extent and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration loaded\n",
      "  Basin: BasinLitani.shp\n",
      "  Date range: 2020-01-01 to 2020-03-31\n",
      "  WaPOR level: 2\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION - Update these paths for your basin\n",
    "# =============================================================================\n",
    "\n",
    "# Basin shapefile path\n",
    "BASIN_SHP = r\"D:\\Papers and Journals\\WAPORWA\\data\\Litani\\BasinLitani.shp\"\n",
    "\n",
    "# Output folder for WaPOR data\n",
    "INPUT_FOLDER = r\"D:\\Papers and Journals\\WAPORWA\\data\\Litani\\Input\"\n",
    "\n",
    "# Main directory for processed data\n",
    "MAIN_DIR = r\"D:\\Papers and Journals\\WAPORWA\\data\\Litani\\Main\"\n",
    "\n",
    "# Global datasets\n",
    "GLOBAL_GRAND_RESERVOIR = r\"D:\\Papers and Journals\\WAPORWA\\data\\Global\\GRanD\\GRanD_reservoirs_v1_1_fixed.shp\"\n",
    "WDPA_SHAPEFILE = r\"D:\\Papers and Journals\\WAPORWA\\data\\Global\\WDPA\\WDPA_CatIandII_17countries.shp\"\n",
    "\n",
    "# Date range for data download\n",
    "START_DATE = '2020-01-01'\n",
    "END_DATE = '2020-03-31'\n",
    "\n",
    "# WaPOR data level (1 = continental 300m, 2 = national 100m)\n",
    "WAPOR_LEVEL = 2\n",
    "\n",
    "# Create output directories\n",
    "os.makedirs(INPUT_FOLDER, exist_ok=True)\n",
    "os.makedirs(MAIN_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"✓ Configuration loaded\")\n",
    "print(f\"  Basin: {os.path.basename(BASIN_SHP)}\")\n",
    "print(f\"  Date range: {START_DATE} to {END_DATE}\")\n",
    "print(f\"  WaPOR level: {WAPOR_LEVEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Basin Bounding Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basin Bounding Box:\n",
      "  Longitude: 35.229167 to 36.400000\n",
      "  Latitude:  33.100000 to 34.050000\n",
      "\n",
      "✓ Bounding box extracted successfully\n"
     ]
    }
   ],
   "source": [
    "# Load basin shapefile and extract bounding box\n",
    "import shapefile\n",
    "\n",
    "shape = shapefile.Reader(BASIN_SHP)\n",
    "xmin, ymin, xmax, ymax = shape.bbox\n",
    "\n",
    "print(\"Basin Bounding Box:\")\n",
    "print(f\"  Longitude: {xmin:.6f} to {xmax:.6f}\")\n",
    "print(f\"  Latitude:  {ymin:.6f} to {ymax:.6f}\")\n",
    "\n",
    "# Define lat/lon limits with buffer for different datasets\n",
    "# Larger buffer for coarser resolution data (L1)\n",
    "latlim_L1 = [ymin - 0.25, ymax + 0.25]\n",
    "lonlim_L1 = [xmin - 0.25, xmax + 0.25]\n",
    "\n",
    "# Exact bbox for fine resolution data (L2)\n",
    "latlim_L2 = [ymin, ymax]\n",
    "lonlim_L2 = [xmin, xmax]\n",
    "\n",
    "print(f\"\\n✓ Bounding box extracted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Monthly Reference Evapotranspiration (L1/L2-RET-M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (RET_monthly.py, line 54)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\Zuhail\\anaconda3\\envs\\waporwa\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3457\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Zuhail\\AppData\\Local\\Temp\\ipykernel_17036\\586742514.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    import WaPOR.RET_monthly as RETv3\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"D:\\Papers and Journals\\WAPORWA\\modules\\WaPOR\\RET_monthly.py\"\u001b[1;36m, line \u001b[1;32m54\u001b[0m\n\u001b[1;33m    if level == 1:\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "import WaPOR.RET_monthly as RETv3\n",
    "latlim_L1 = [ymin - 0.25, ymax + 0.25]\n",
    "lonlim_L1 = [xmin - 0.25, xmax + 0.25]\n",
    "\n",
    "RETv3.main(\n",
    "    Dir=INPUT_FOLDER,\n",
    "    Startdate=START_DATE,\n",
    "    Enddate=END_DATE,\n",
    "    latlim=latlim_L1,\n",
    "    lonlim=lonlim_L1,\n",
    "    level=1,   # 1 or 2\n",
    "    version=3,\n",
    "    Waitbar=1\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'urllib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11748\\2537021109.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp_raw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'urllib' is not defined"
     ]
    }
   ],
   "source": [
    "urllib.request.urlretrieve(url, tmp_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Download WaPOR v3 Data\n",
    "\n",
    "This section downloads all required WaPOR datasets using the new v3 API.\n",
    "**Note:** No API token is required for WaPOR v3!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Daily Precipitation (L1-PCP-E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DOWNLOADING DAILY PRECIPITATION (L1-PCP-E)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "WaPOR.PCP_daily(\n",
    "    Dir=INPUT_FOLDER,\n",
    "    Startdate=START_DATE,\n",
    "    Enddate=END_DATE,\n",
    "    latlim=latlim_L1,\n",
    "    lonlim=lonlim_L1,\n",
    "    version=3,  # Always uses v3\n",
    "    Waitbar=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Daily precipitation download complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Monthly Precipitation (L1-PCP-M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DOWNLOADING MONTHLY PRECIPITATION (L1-PCP-M)\n",
      "================================================================================\n",
      "\n",
      "Downloading WaPOR v3 mapset: L1-PCP-M\n",
      "Date range: 2020-01-01 to 2020-03-31\n",
      "Bounding box: lat [32.8499999999998, 34.29999999999972], lon [34.97916666666592, 36.649999999999224]\n",
      "Found 3 rasters to download\n",
      "Using scale factor: 0.1\n",
      "[1/3] Downloading: L1-PCP-M.2020-01.tif\n",
      "[2/3] Downloading: L1-PCP-M.2020-02.tif\n",
      "[3/3] Downloading: L1-PCP-M.2020-03.tif\n",
      "Finished downloading L1-PCP-M\n",
      "\n",
      "✓ Monthly precipitation download complete\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"DOWNLOADING MONTHLY PRECIPITATION (L1-PCP-M)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "WaPOR.PCP_monthly(\n",
    "    Dir=INPUT_FOLDER,\n",
    "    Startdate=START_DATE,\n",
    "    Enddate=END_DATE,\n",
    "    latlim=latlim_L1,\n",
    "    lonlim=lonlim_L1,\n",
    "    version=3,\n",
    "    Waitbar=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Monthly precipitation download complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Monthly Actual Evapotranspiration (L1/L2-AETI-M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gdal\n",
    "\n",
    "# Windows-safe removal for GDAL temp files\n",
    "def safe_remove(path):\n",
    "    try:\n",
    "        gdal.Unlink(path)    # GDAL cleanup\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        os.remove(path)      # Normal cleanup\n",
    "    except PermissionError:\n",
    "        pass\n",
    "\n",
    "# Patch remove globally\n",
    "os.remove = safe_remove\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading WaPOR v3 Yearly Precipitation (L1-PCP-A) from 2019-01-01 to 2020-01-31\n",
      "Downloading year 2019: WAPOR-3.L1-PCP-A.2019\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'D:\\\\Papers and Journals\\\\WAPORWA\\\\data\\\\Litani\\\\Input\\\\L1-PCP-A\\\\_raw_2019.tif'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3588\\325740946.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mlonlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlonlim_L1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mWaitbar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m )\n",
      "\u001b[1;32mD:\\Papers and Journals\\WAPORWA\\modules\\WaPOR\\PCP_yearly.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m(Dir, Startdate, Enddate, latlim, lonlim, version, Waitbar)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_raw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_raw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;31m# Read, scale, save\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'D:\\\\Papers and Journals\\\\WAPORWA\\\\data\\\\Litani\\\\Input\\\\L1-PCP-A\\\\_raw_2019.tif'"
     ]
    }
   ],
   "source": [
    "import WaPOR.PCP_yearly as PCPY  # if placed inside WaPOR/modules\n",
    "\n",
    "PCPY.main(\n",
    "    Dir=INPUT_FOLDER,\n",
    "    Startdate=\"2019-01-01\",\n",
    "    Enddate=\"2020-01-31\",\n",
    "    latlim=latlim_L1,\n",
    "    lonlim=lonlim_L1,\n",
    "    version=3,\n",
    "    Waitbar=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing URL: https://storage.googleapis.com/fao-gismgr-wapor-3-data/DATA/WAPOR-3/MAPSET/L2-I-D/WAPOR-3.L2-I-D.2018-01-D1.tif\n",
      "Status: 200\n",
      "Content-Length: 351983828\n"
     ]
    }
   ],
   "source": [
    "# Check if interception data exists\n",
    "import requests\n",
    "from WaPOR.waporv3_api import base_url, collect_responses\n",
    "\n",
    "mapset_url = f\"{base_url}/L2-I-D/rasters\"\n",
    "rasters = collect_responses(mapset_url, info=[\"code\", \"downloadUrl\"])\n",
    "\n",
    "# Test first URL\n",
    "if rasters:\n",
    "    code, url = rasters[0]\n",
    "    print(f\"Testing URL: {url}\")\n",
    "    response = requests.head(url, timeout=30)\n",
    "    print(f\"Status: {response.status_code}\")\n",
    "    print(f\"Content-Length: {response.headers.get('Content-Length', 'Unknown')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "✓ Downloaded: 351983828 bytes\n",
      "Cropping...\n"
     ]
    },
    {
     "ename": "SystemError",
     "evalue": "<built-in function wrapper_GDALWarpDestName> returned NULL without setting an error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSystemError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7240\\798839472.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cropping...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m ds = gdal.Warp(output_path, download_path, \n\u001b[1;32m---> 25\u001b[1;33m                options=gdal.WarpOptions(outputBounds=bbox, dstNodata=-9999))\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"✓ Cropped successfully\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\waporwa\\lib\\site-packages\\osgeo\\gdal.py\u001b[0m in \u001b[0;36mWarp\u001b[1;34m(destNameOrDestDS, srcDSOrSrcDSTab, **kwargs)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_str_or_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestNameOrDestDS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper_GDALWarpDestName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestNameOrDestDS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrcDSTab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper_GDALWarpDestDS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestNameOrDestDS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrcDSTab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\waporwa\\lib\\site-packages\\osgeo\\gdal.py\u001b[0m in \u001b[0;36mwrapper_GDALWarpDestName\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3187\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwrapper_GDALWarpDestName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3188\u001b[0m     \u001b[1;34m\"\"\"wrapper_GDALWarpDestName(char const * dest, int object_list_count, GDALWarpAppOptions warpAppOptions, GDALProgressFunc callback=0, void * callback_data=None) -> Dataset\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3189\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_gdal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrapper_GDALWarpDestName\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3190\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mGDALVectorTranslateOptions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3191\u001b[0m     \u001b[1;34m\"\"\"Proxy of C++ GDALVectorTranslateOptions class.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemError\u001b[0m: <built-in function wrapper_GDALWarpDestName> returned NULL without setting an error"
     ]
    }
   ],
   "source": [
    "# Test the two-step approach manually\n",
    "import requests\n",
    "from osgeo import gdal\n",
    "import os\n",
    "\n",
    "url = \"https://storage.googleapis.com/fao-gismgr-wapor-3-data/DATA/WAPOR-3/MAPSET/L2-I-D/WAPOR-3.L2-I-D.2018-01-D1.tif\"\n",
    "test_dir = r\"D:\\test\"\n",
    "os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "# Step 1: Download\n",
    "download_path = os.path.join(test_dir, \"full_download.tif\")\n",
    "print(\"Downloading...\")\n",
    "response = requests.get(url, stream=True)\n",
    "with open(download_path, 'wb') as f:\n",
    "    for chunk in response.iter_content(chunk_size=8192):\n",
    "        if chunk:\n",
    "            f.write(chunk)\n",
    "print(f\"✓ Downloaded: {os.path.getsize(download_path)} bytes\")\n",
    "\n",
    "# Step 2: Crop\n",
    "bbox = [35.2, 33.1, 36.4, 34.0]  # Your basin bbox\n",
    "output_path = os.path.join(test_dir, \"cropped.tif\")\n",
    "print(\"Cropping...\")\n",
    "ds = gdal.Warp(output_path, download_path, \n",
    "               options=gdal.WarpOptions(outputBounds=bbox, dstNodata=-9999))\n",
    "if ds:\n",
    "    print(\"✓ Cropped successfully\")\n",
    "    ds = None\n",
    "else:\n",
    "    print(\"✗ Crop failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Zuhail\\AppData\\Local\\Temp\\ipykernel_7240\\1170236020.py\", line 12, in assert_bigtiff_read_support\n",
      "    ds = gdal.Open(r\"D:\\test\\full_download.tif\", gdal.GA_ReadOnly)\n",
      "  File \"C:\\Users\\Zuhail\\anaconda3\\envs\\waporwa\\lib\\site-packages\\osgeo\\gdal.py\", line 3087, in Open\n",
      "    return _gdal.Open(*args)\n",
      "RuntimeError: This is a BigTIFF file.  BigTIFF is not supported by this version of GDAL and libtiff.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Zuhail\\anaconda3\\envs\\waporwa\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Zuhail\\AppData\\Local\\Temp\\ipykernel_7240\\1170236020.py\", line 27, in <module>\n",
      "    assert_bigtiff_read_support()\n",
      "  File \"C:\\Users\\Zuhail\\AppData\\Local\\Temp\\ipykernel_7240\\1170236020.py\", line 17, in assert_bigtiff_read_support\n",
      "    \"Your GDAL build lacks BigTIFF support. Install GDAL from conda-forge or OSGeo4W (64-bit).\"\n",
      "SystemExit: Your GDAL build lacks BigTIFF support. Install GDAL from conda-forge or OSGeo4W (64-bit).\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Zuhail\\anaconda3\\envs\\waporwa\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Zuhail\\anaconda3\\envs\\waporwa\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Zuhail\\anaconda3\\envs\\waporwa\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Zuhail\\anaconda3\\envs\\waporwa\\lib\\inspect.py\", line 1502, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7240\\1170236020.py\u001b[0m in \u001b[0;36massert_bigtiff_read_support\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgdal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"D:\\test\\full_download.tif\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgdal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGA_ReadOnly\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\waporwa\\lib\\site-packages\\osgeo\\gdal.py\u001b[0m in \u001b[0;36mOpen\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3086\u001b[0m     \u001b[1;34m\"\"\"Open(char const * utf8_path, GDALAccess eAccess) -> Dataset\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3087\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_gdal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3088\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: This is a BigTIFF file.  BigTIFF is not supported by this version of GDAL and libtiff.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7240\\1170236020.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[0massert_bigtiff_read_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"OK: BigTIFF supported, proceed to gdal.Warp.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7240\\1170236020.py\u001b[0m in \u001b[0;36massert_bigtiff_read_support\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m             raise SystemExit(\n\u001b[1;32m---> 17\u001b[1;33m                 \u001b[1;34m\"Your GDAL build lacks BigTIFF support. Install GDAL from conda-forge or OSGeo4W (64-bit).\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             )\n",
      "\u001b[1;31mSystemExit\u001b[0m: Your GDAL build lacks BigTIFF support. Install GDAL from conda-forge or OSGeo4W (64-bit).",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\waporwa\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2069\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m   2070\u001b[0m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[1;32m-> 2071\u001b[1;33m                                                                      value))\n\u001b[0m\u001b[0;32m   2072\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2073\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\waporwa\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \"\"\"\n\u001b[1;32m--> 754\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\waporwa\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n\u001b[0;32m    632\u001b[0m                 \u001b[1;33m+\u001b[0m \u001b[0mchained_exception_message\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m                 + out_list)\n\u001b[0m\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\waporwa\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1368\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\waporwa\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1268\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1269\u001b[0m             )\n\u001b[0;32m   1270\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Minimal'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\waporwa\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[1;32m-> 1125\u001b[1;33m                                                                tb_offset)\n\u001b[0m\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[1;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\waporwa\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\waporwa\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# file: tools/check_bigtiff_support.py\n",
    "\"\"\"\n",
    "Assert BigTIFF read support before attempting Warp. Why: avoids opaque NULL errors.\n",
    "\"\"\"\n",
    "from osgeo import gdal\n",
    "\n",
    "gdal.UseExceptions()\n",
    "\n",
    "def assert_bigtiff_read_support():\n",
    "    # If this raises on your file, your GDAL/libtiff lacks BigTIFF support.\n",
    "    try:\n",
    "        ds = gdal.Open(r\"D:\\test\\full_download.tif\", gdal.GA_ReadOnly)\n",
    "    except RuntimeError as e:\n",
    "        msg = str(e)\n",
    "        if \"BigTIFF\" in msg or \"not supported\" in msg:\n",
    "            raise SystemExit(\n",
    "                \"Your GDAL build lacks BigTIFF support. Install GDAL from conda-forge or OSGeo4W (64-bit).\"\n",
    "            )\n",
    "        raise\n",
    "    finally:\n",
    "        try:\n",
    "            ds = None\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    assert_bigtiff_read_support()\n",
    "    print(\"OK: BigTIFF supported, proceed to gdal.Warp.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (158106904.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Zuhail\\AppData\\Local\\Temp\\ipykernel_7240\\158106904.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    gdalinfo --format GTiff\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "gdalinfo --format GTiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DOWNLOADING MONTHLY ACTUAL ET (L2-AETI-M)\n",
      "================================================================================\n",
      "\n",
      "Downloading WaPOR v3 mapset: L1-AETI-M\n",
      "Date range: 2020-01-01 to 2020-03-31\n",
      "Bounding box: lat [33.0999999999998, 34.04999999999972], lon [35.22916666666592, 36.399999999999224]\n",
      "Found 3 rasters to download\n",
      "Using scale factor: 0.1\n",
      "[1/3] Downloading: L1-AETI-M.2020-01.tif\n",
      "ERROR downloading L1-AETI-M.2020-01.tif: <built-in function wrapper_GDALWarpDestName> returned NULL without setting an error\n",
      "[2/3] Downloading: L1-AETI-M.2020-02.tif\n",
      "ERROR downloading L1-AETI-M.2020-02.tif: <built-in function wrapper_GDALWarpDestName> returned NULL without setting an error\n",
      "[3/3] Downloading: L1-AETI-M.2020-03.tif\n",
      "ERROR downloading L1-AETI-M.2020-03.tif: <built-in function wrapper_GDALWarpDestName> returned NULL without setting an error\n",
      "Finished downloading L1-AETI-M\n",
      "\n",
      "✓ Monthly actual ET download complete\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(f\"DOWNLOADING MONTHLY ACTUAL ET (L{WAPOR_LEVEL}-AETI-M)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "WaPOR.AET_monthly(\n",
    "    Dir=INPUT_FOLDER,\n",
    "    Startdate=START_DATE,\n",
    "    Enddate=END_DATE,\n",
    "    latlim=latlim_L2 if WAPOR_LEVEL == 2 else latlim_L1,\n",
    "    lonlim=lonlim_L2 if WAPOR_LEVEL == 2 else lonlim_L1,\n",
    "    level=1,\n",
    "    version=3,\n",
    "    Waitbar=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Monthly actual ET download complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Dekadal Interception (L1/L2-I-D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DOWNLOADING DEKADAL INTERCEPTION (L2-I-D)\n",
      "================================================================================\n",
      "\n",
      "Downloading WaPOR v3 mapset: L2-I-D\n",
      "Date range: 2020-01-01 to 2020-03-31\n",
      "Bounding box: lat [33.0999999999998, 34.04999999999972], lon [35.22916666666592, 36.399999999999224]\n",
      "Found 9 rasters to download\n",
      "Using scale factor: 0.1\n",
      "[1/9] Downloading: L2-I-D.2020-01-D1.tif\n",
      "ERROR downloading L2-I-D.2020-01-D1.tif: <built-in function wrapper_GDALWarpDestName> returned NULL without setting an error\n",
      "[2/9] Downloading: L2-I-D.2020-01-D2.tif\n",
      "ERROR downloading L2-I-D.2020-01-D2.tif: <built-in function wrapper_GDALWarpDestName> returned NULL without setting an error\n",
      "[3/9] Downloading: L2-I-D.2020-01-D3.tif\n",
      "ERROR downloading L2-I-D.2020-01-D3.tif: <built-in function wrapper_GDALWarpDestName> returned NULL without setting an error\n",
      "[4/9] Downloading: L2-I-D.2020-02-D1.tif\n",
      "ERROR downloading L2-I-D.2020-02-D1.tif: <built-in function wrapper_GDALWarpDestName> returned NULL without setting an error\n",
      "[5/9] Downloading: L2-I-D.2020-02-D2.tif\n",
      "ERROR downloading L2-I-D.2020-02-D2.tif: <built-in function wrapper_GDALWarpDestName> returned NULL without setting an error\n",
      "[6/9] Downloading: L2-I-D.2020-02-D3.tif\n",
      "ERROR downloading L2-I-D.2020-02-D3.tif: <built-in function wrapper_GDALWarpDestName> returned NULL without setting an error\n",
      "[7/9] Downloading: L2-I-D.2020-03-D1.tif\n",
      "ERROR downloading L2-I-D.2020-03-D1.tif: <built-in function wrapper_GDALWarpDestName> returned NULL without setting an error\n",
      "[8/9] Downloading: L2-I-D.2020-03-D2.tif\n",
      "ERROR downloading L2-I-D.2020-03-D2.tif: <built-in function wrapper_GDALWarpDestName> returned NULL without setting an error\n",
      "[9/9] Downloading: L2-I-D.2020-03-D3.tif\n",
      "ERROR downloading L2-I-D.2020-03-D3.tif: <built-in function wrapper_GDALWarpDestName> returned NULL without setting an error\n",
      "Finished downloading L2-I-D\n",
      "\n",
      "✓ Dekadal interception download complete\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*80)\n",
    "print(f\"DOWNLOADING DEKADAL INTERCEPTION (L{WAPOR_LEVEL}-I-D)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "WaPOR.I_dekadal(\n",
    "    Dir=INPUT_FOLDER,\n",
    "    Startdate=START_DATE,\n",
    "    Enddate=END_DATE,\n",
    "    latlim=latlim_L2 if WAPOR_LEVEL == 2 else latlim_L1,\n",
    "    lonlim=lonlim_L2 if WAPOR_LEVEL == 2 else lonlim_L1,\n",
    "    level=WAPOR_LEVEL,\n",
    "    version=3,\n",
    "    Waitbar=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Dekadal interception download complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Annual Land Cover Classification (L1/L2-LCC-A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(f\"DOWNLOADING ANNUAL LAND COVER (L{WAPOR_LEVEL}-LCC-A)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "WaPOR.LCC_yearly(\n",
    "    Dir=INPUT_FOLDER,\n",
    "    Startdate=START_DATE,\n",
    "    Enddate=END_DATE,\n",
    "    latlim=latlim_L2 if WAPOR_LEVEL == 2 else latlim_L1,\n",
    "    lonlim=lonlim_L2 if WAPOR_LEVEL == 2 else lonlim_L1,\n",
    "    level=WAPOR_LEVEL,\n",
    "    version=3,\n",
    "    Waitbar=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ Annual land cover download complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Download Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DOWNLOAD SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check downloaded data\n",
    "mapsets = [\n",
    "    'L1-PCP-E',\n",
    "    'L1-PCP-M',\n",
    "    f'L{WAPOR_LEVEL}-RET-M',\n",
    "    f'L{WAPOR_LEVEL}-AETI-M',\n",
    "    f'L{WAPOR_LEVEL}-I-D',\n",
    "    f'L{WAPOR_LEVEL}-LCC-A'\n",
    "]\n",
    "\n",
    "for mapset in mapsets:\n",
    "    mapset_dir = os.path.join(INPUT_FOLDER, mapset)\n",
    "    if os.path.exists(mapset_dir):\n",
    "        n_files = len(glob.glob(os.path.join(mapset_dir, '*.tif')))\n",
    "        print(f\"✓ {mapset:20s}: {n_files:4d} files\")\n",
    "    else:\n",
    "        print(f\"✗ {mapset:20s}: Directory not found\")\n",
    "\n",
    "print(\"\\n✓ All WaPOR v3 data downloads complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Reclassify LCC to LUWA\n",
    "\n",
    "Convert WaPOR Land Cover Classification to Land Use for Water Accounting (LUWA) classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from WA.LCC_to_LUWA import Rasterize_shape_basin, Adjust_GRaND_reservoir, LCC_to_LUWA\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"RECLASSIFYING LCC TO LUWA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define paths\n",
    "LCC_FOLDER = os.path.join(INPUT_FOLDER, f'L{WAPOR_LEVEL}-LCC-A')\n",
    "LCC_fhs = sorted(glob.glob(os.path.join(LCC_FOLDER, '*.tif')))\n",
    "\n",
    "if len(LCC_fhs) == 0:\n",
    "    print(f\"ERROR: No LCC files found in {LCC_FOLDER}\")\n",
    "else:\n",
    "    print(f\"Found {len(LCC_fhs)} LCC files to process\")\n",
    "    \n",
    "    # Use first LCC file as template\n",
    "    WaPOR_LCC = LCC_fhs[0]\n",
    "    \n",
    "    # Optional: Adjust reservoirs (set to None if not needed)\n",
    "    Resrv_to_Lake = None  # GeoTIFF of reservoirs that are actually natural lakes\n",
    "    Lake_to_Reserv = None  # GeoTIFF of natural lakes that are actually reservoirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Create Reservoir Raster Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCreating reservoir raster map...\")\n",
    "\n",
    "# Create output directory\n",
    "Reservoir_dir = os.path.join(MAIN_DIR, 'Reservoir')\n",
    "os.makedirs(Reservoir_dir, exist_ok=True)\n",
    "\n",
    "Basin_Reservoir_tif = os.path.join(Reservoir_dir, 'Reservoir_basin.tif')\n",
    "\n",
    "# Adjust reservoir if custom shapefiles provided\n",
    "if (Resrv_to_Lake is not None) and (Lake_to_Reserv is not None):\n",
    "    print(\"  Adjusting reservoirs with custom classifications...\")\n",
    "    Adjust_GRaND_reservoir(\n",
    "        Basin_Reservoir_tif,\n",
    "        WaPOR_LCC,\n",
    "        GLOBAL_GRAND_RESERVOIR,\n",
    "        Resrv_to_Lake,\n",
    "        Lake_to_Reserv\n",
    "    )\n",
    "else:\n",
    "    print(\"  Using standard GRanD reservoir classification...\")\n",
    "    Rasterize_shape_basin(\n",
    "        GLOBAL_GRAND_RESERVOIR,\n",
    "        WaPOR_LCC,\n",
    "        Basin_Reservoir_tif\n",
    "    )\n",
    "\n",
    "print(f\"✓ Reservoir map created: {Basin_Reservoir_tif}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Create Protected Area Raster Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCreating protected area raster map...\")\n",
    "\n",
    "# Create output directory\n",
    "Protected_dir = os.path.join(MAIN_DIR, 'Protected')\n",
    "os.makedirs(Protected_dir, exist_ok=True)\n",
    "\n",
    "ProtectedArea_tif = os.path.join(Protected_dir, 'ProtectedArea_basin.tif')\n",
    "\n",
    "Rasterize_shape_basin(\n",
    "    WDPA_SHAPEFILE,\n",
    "    WaPOR_LCC,\n",
    "    ProtectedArea_tif\n",
    ")\n",
    "\n",
    "print(f\"✓ Protected area map created: {ProtectedArea_tif}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Convert LCC to LUWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nReclassifying LCC to LUWA...\")\n",
    "\n",
    "# Create output directory\n",
    "LUWA_dir = os.path.join(MAIN_DIR, 'data', 'luwa')\n",
    "os.makedirs(LUWA_dir, exist_ok=True)\n",
    "\n",
    "# Process each LCC file\n",
    "for i, fh in enumerate(LCC_fhs, 1):\n",
    "    print(f\"  [{i}/{len(LCC_fhs)}] Processing {os.path.basename(fh)}...\")\n",
    "    LCC_to_LUWA(\n",
    "        fh,\n",
    "        LUWA_dir,\n",
    "        ProtectedArea_tif,\n",
    "        Basin_Reservoir_tif\n",
    "    )\n",
    "\n",
    "n_luwa = len(glob.glob(os.path.join(LUWA_dir, '*.tif')))\n",
    "print(f\"\\n✓ LUWA reclassification complete: {n_luwa} files created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Create Monthly Interception\n",
    "\n",
    "Aggregate dekadal interception data to monthly totals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"AGGREGATING DEKADAL INTERCEPTION TO MONTHLY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define input and output folders\n",
    "Dekadal_I_folder = os.path.join(INPUT_FOLDER, f'L{WAPOR_LEVEL}-I-D')\n",
    "Monthly_I_folder = os.path.join(INPUT_FOLDER, f'L{WAPOR_LEVEL}-I-M')\n",
    "os.makedirs(Monthly_I_folder, exist_ok=True)\n",
    "\n",
    "# Get list of dekadal rasters\n",
    "input_fhs = sorted(glob.glob(os.path.join(Dekadal_I_folder, '*.tif')))\n",
    "print(f\"Found {len(input_fhs)} dekadal interception files\")\n",
    "\n",
    "if len(input_fhs) == 0:\n",
    "    print(\"ERROR: No dekadal interception files found\")\n",
    "else:\n",
    "    # Get template for georeferencing\n",
    "    driver, NDV, xsize, ysize, GeoT, Projection = gis.GetGeoInfo(input_fhs[0])\n",
    "    \n",
    "    # Get month dates\n",
    "    month_dates = pd.date_range(START_DATE, END_DATE, freq='MS')\n",
    "    print(f\"Processing {len(month_dates)} months...\\n\")\n",
    "    \n",
    "    # Process each month\n",
    "    for idx, date in enumerate(month_dates, 1):\n",
    "        year = date.year\n",
    "        month = date.month\n",
    "        \n",
    "        print(f\"  [{idx}/{len(month_dates)}] Processing {year}-{month:02d}...\")\n",
    "        \n",
    "        # Find all files for this month by parsing filenames\n",
    "        month_fhs = []\n",
    "        for in_fh in input_fhs:\n",
    "            fname = os.path.basename(in_fh)\n",
    "            # Parse year-month from filename (format: WAPOR.v3_mm-dekad-1_YYYY-MM-D*.tif)\n",
    "            if f'{year}-{month:02d}' in fname:\n",
    "                month_fhs.append(in_fh)\n",
    "        \n",
    "        if len(month_fhs) == 0:\n",
    "            print(f\"    WARNING: No dekadal files found for {year}-{month:02d}\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"    Found {len(month_fhs)} dekadal files for this month\")\n",
    "        \n",
    "        # Sum dekadal values to get monthly total\n",
    "        SumArray = np.zeros((ysize, xsize), dtype=np.float32)\n",
    "        for fh in month_fhs:\n",
    "            Array = gis.OpenAsArray(fh, nan_values=True)\n",
    "            SumArray = np.nansum([SumArray, Array], axis=0)\n",
    "        \n",
    "        # Save monthly file\n",
    "        out_fh = os.path.join(\n",
    "            Monthly_I_folder,\n",
    "            f'I_WAPOR.v3_level{WAPOR_LEVEL}_mm-month-1_monthly_{year:04d}.{month:02d}.tif'\n",
    "        )\n",
    "        gis.CreateGeoTiff(out_fh, SumArray, driver, NDV, xsize, ysize, GeoT, Projection)\n",
    "    \n",
    "    n_monthly = len(glob.glob(os.path.join(Monthly_I_folder, '*.tif')))\n",
    "    print(f\"\\n✓ Monthly interception aggregation complete: {n_monthly} files created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Create Monthly Rainy Days\n",
    "\n",
    "Calculate the number of rainy days per month from daily precipitation data.\n",
    "A rainy day is defined as a day with precipitation > 0.201 mm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CALCULATING MONTHLY RAINY DAYS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define paths\n",
    "Data_Path_P = os.path.join(INPUT_FOLDER, 'L1-PCP-E')\n",
    "Data_Path_RD = os.path.join(INPUT_FOLDER, 'Rainy_Days')\n",
    "os.makedirs(Data_Path_RD, exist_ok=True)\n",
    "\n",
    "# Get list of daily precipitation files\n",
    "daily_files = sorted(glob.glob(os.path.join(Data_Path_P, '*daily*.tif')))\n",
    "print(f\"Found {len(daily_files)} daily precipitation files\\n\")\n",
    "\n",
    "if len(daily_files) == 0:\n",
    "    print(\"ERROR: No daily precipitation files found\")\n",
    "else:\n",
    "    # Generate list of months to process\n",
    "    Dates = pd.date_range(START_DATE, END_DATE, freq='MS')\n",
    "    \n",
    "    for idx, Date in enumerate(Dates, 1):\n",
    "        year = Date.year\n",
    "        month = Date.month\n",
    "        daysinmonth = calendar.monthrange(year, month)[1]\n",
    "        \n",
    "        print(f\"  [{idx}/{len(Dates)}] Processing {year}-{month:02d} ({daysinmonth} days)...\")\n",
    "        \n",
    "        # Find all files for this month\n",
    "        # Format: P_WAPOR.v3_mm-day-1_daily_YYYY.MM.DD.tif\n",
    "        month_files = [f for f in daily_files if f'daily_{year}.{month:02d}.' in f]\n",
    "        \n",
    "        # Check if we have all days\n",
    "        if len(month_files) != daysinmonth:\n",
    "            print(f\"    WARNING: Expected {daysinmonth} files, found {len(month_files)}\")\n",
    "            if len(month_files) == 0:\n",
    "                continue\n",
    "        \n",
    "        # Initialize arrays\n",
    "        first_file = month_files[0]\n",
    "        driver, NDV, xsize, ysize, GeoT, Projection = gis.GetGeoInfo(first_file)\n",
    "        P_Daily = np.zeros([len(month_files), ysize, xsize], dtype=np.float32)\n",
    "        \n",
    "        # Load all daily data for the month\n",
    "        for i, file_path in enumerate(sorted(month_files)):\n",
    "            Data = gis.OpenAsArray(file_path, nan_values=True)\n",
    "            Data[Data < 0] = 0  # Remove negative values\n",
    "            P_Daily[i, :, :] = Data\n",
    "        \n",
    "        # Define rainy days (precipitation > 0.201 mm)\n",
    "        P_Daily_binary = np.where(P_Daily > 0.201, 1, 0)\n",
    "        \n",
    "        # Count number of rainy days\n",
    "        RD_one_month = np.sum(P_Daily_binary, axis=0).astype(np.float32)\n",
    "        \n",
    "        # Save output\n",
    "        Outname = os.path.join(\n",
    "            Data_Path_RD,\n",
    "            f'Rainy_Days_NumOfDays_monthly_{year:04d}.{month:02d}.01.tif'\n",
    "        )\n",
    "        gis.CreateGeoTiff(Outname, RD_one_month, driver, NDV, xsize, ysize, GeoT, Projection)\n",
    "    \n",
    "    n_rainy_days = len(glob.glob(os.path.join(Data_Path_RD, '*.tif')))\n",
    "    print(f\"\\n✓ Monthly rainy days calculation complete: {n_rainy_days} files created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL PROCESSING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary_data = {\n",
    "    'Dataset': [],\n",
    "    'Location': [],\n",
    "    'Files': []\n",
    "}\n",
    "\n",
    "# Check all output folders\n",
    "check_folders = [\n",
    "    ('Daily Precipitation', os.path.join(INPUT_FOLDER, 'L1-PCP-E')),\n",
    "    ('Monthly Precipitation', os.path.join(INPUT_FOLDER, 'L1-PCP-M')),\n",
    "    (f'Monthly Reference ET (L{WAPOR_LEVEL})', os.path.join(INPUT_FOLDER, f'L{WAPOR_LEVEL}-RET-M')),\n",
    "    (f'Monthly Actual ET (L{WAPOR_LEVEL})', os.path.join(INPUT_FOLDER, f'L{WAPOR_LEVEL}-AETI-M')),\n",
    "    (f'Dekadal Interception (L{WAPOR_LEVEL})', os.path.join(INPUT_FOLDER, f'L{WAPOR_LEVEL}-I-D')),\n",
    "    (f'Monthly Interception (L{WAPOR_LEVEL})', os.path.join(INPUT_FOLDER, f'L{WAPOR_LEVEL}-I-M')),\n",
    "    (f'Land Cover (L{WAPOR_LEVEL})', os.path.join(INPUT_FOLDER, f'L{WAPOR_LEVEL}-LCC-A')),\n",
    "    ('LUWA', os.path.join(MAIN_DIR, 'data', 'luwa')),\n",
    "    ('Rainy Days', os.path.join(INPUT_FOLDER, 'Rainy_Days')),\n",
    "]\n",
    "\n",
    "for name, folder in check_folders:\n",
    "    if os.path.exists(folder):\n",
    "        n_files = len(glob.glob(os.path.join(folder, '*.tif')))\n",
    "        summary_data['Dataset'].append(name)\n",
    "        summary_data['Location'].append(folder)\n",
    "        summary_data['Files'].append(n_files)\n",
    "\n",
    "# Create summary dataframe\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "print(\"\\n\")\n",
    "print(df_summary.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ ALL PROCESSING COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nData ready for water accounting analysis!\")\n",
    "print(f\"Input folder: {INPUT_FOLDER}\")\n",
    "print(f\"Main folder:  {MAIN_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
